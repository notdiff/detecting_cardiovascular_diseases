{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVnWB-3HjwHn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb focal_loss_torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict, OrderedDict\n",
        "from focal_loss.focal_loss import FocalLoss\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "RXDm2YGFkh9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Подгрузка данных\n",
        "\n"
      ],
      "metadata": {
        "id": "us6h7yvUWXir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1Rt0I7Svrx77tFMCsNubEQ-cDY8hD-iCk #r_peaks.zip\n",
        "!gdown 1GWyzUaz_mOwYDbLuopjroIcfngjSJWkD #labels\n",
        "!unzip r_peaks.zip"
      ],
      "metadata": {
        "id": "guLiPcGn790B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " 'NORM' : 0,\n",
        " 'IMI': 1,\n",
        " 'NDT': 2,\n",
        " 'NST_': 3,\n",
        " 'LVH': 4,\n",
        " 'LAFB': 5,\n",
        " 'IRBBB': 6,\n",
        " 'IVCD': 7,\n",
        " 'ASMI': 8,\n",
        " 'AMI': 9,\n",
        " 'ISCAL': 10,\n",
        " '1AVB': 11,\n",
        " 'ILMI': 12,\n",
        " 'ISC_': 13,\n",
        " 'CRBBB': 14,\n",
        " 'CLBBB': 15,\n",
        " 'LAO/LAE': 16}\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "tKzklbFrU-WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Разделение датасета\n",
        "Для одного target_class, все остальные классы обозначаются как 0"
      ],
      "metadata": {
        "id": "_5STPLkohteR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv(\"train_val_labels.csv\")\n",
        "#в target_class номер класса для обучения одной из сетей\n",
        "target_class = 8\n",
        "left_classes = [i for i in labels.result_class.unique() if i != target_class]\n",
        "num_others = (len(labels[labels.result_class == target_class]) * 2) // 15\n",
        "data = labels[labels.result_class == target_class]\n",
        "data.loc[:, [\"result_class\"]] = 1\n",
        "data.index = range(0, len(data))\n",
        "for cur_class in left_classes:\n",
        "  cur_class_data = labels[(labels.result_class == cur_class)]\n",
        "  cur_class_data = cur_class_data[~cur_class_data.record_name.isin(labels[labels.result_class != cur_class].record_name)]\n",
        "  cur_frame = cur_class_data.sample(n=min(len(cur_class_data), num_others))\n",
        "  cur_frame.loc[:, [\"result_class\"]] = 0\n",
        "  data = pd.concat([data, cur_frame], axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeFOFly7_a4w",
        "outputId": "532ab038-be70-4318-f02c-4aceda3bd49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-62396d917742>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[:, [\"result_class\"]] = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "CJtOW5cAxJEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EcgPTBDataset(Dataset):\n",
        "    def __init__(self, labels, path='/'):\n",
        "        self.x_paths = [labels.iloc[i, 0] for i in range(len(labels))]\n",
        "        self.labels = [labels.iloc[i, 1] for i in range(len(labels))]\n",
        "        self.path = path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        hr = torch.tensor(np.load(self.path + self.x_paths[idx] + '.npy'))[None, :, :]\n",
        "\n",
        "        target = self.labels[idx]\n",
        "\n",
        "        return hr, target"
      ],
      "metadata": {
        "id": "ff8S4sfZk7b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ptb_set = EcgPTBDataset(data, path=\"/content/r_peaks/signals/\")\n",
        "\n",
        "valid_data, train_data = random_split(ptb_set, lengths=[0.1, 0.9])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=1)\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=1)"
      ],
      "metadata": {
        "id": "1UEWfz3elL0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ECGNET"
      ],
      "metadata": {
        "id": "1V_ARXu4kbny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ECGNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ECGNet, self).__init__()\n",
        "    #layer1\n",
        "    self.layer1_conv2d = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1, 25), stride=(1, 2), bias=True)\n",
        "\n",
        "\n",
        "    #layer2\n",
        "    self.layer2_conv2d = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(1, 15), stride=(1, 1), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(1, 15), stride=(1, 2),  bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(1, 15), stride=(1, 1), bias=True)),\n",
        "    ]))\n",
        "    self.layer2_seModule = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    #layer3\n",
        "    self.layer3_conv2d_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=True)),\n",
        "    ]))\n",
        "    self.layer3_seModule_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer3_conv2d_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(5, 1), padding=(2, 0), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(5, 1), padding=(2, 0), bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(5, 1), padding=(2, 0), bias=True)),\n",
        "    ]))\n",
        "    self.layer3_seModule_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer3_conv2d_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(7, 1), padding=(3, 0), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(7, 1), padding=(3, 0), bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(7, 1), padding=(3, 0), bias=True)),\n",
        "    ]))\n",
        "    self.layer3_seModule_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    #layer4\n",
        "    self.layer4_conv1d_short_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 384, kernel_size=3, stride=9, bias=True)),\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 768, kernel_size=3, stride=2, bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv1d(768, 768, kernel_size=3, stride=1, bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv1d(768, 1536, kernel_size=3, stride=2, bias=True)),\n",
        "        (\"bn4\", nn.BatchNorm1d(num_features=1536)),\n",
        "        (\"act4\", nn.ReLU()),\n",
        "        (\"cn4\", nn.Conv1d(1536, 384, kernel_size=3, stride=2, bias=True)),\n",
        "    ]))\n",
        "    self.layer4_seModule_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv1d(384, 48, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv1d(48, 384, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_short_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 384, kernel_size=5, stride=9, bias=True)),\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 768, kernel_size=5, stride=2, padding=2, bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv1d(768, 768, kernel_size=5, stride=2, padding=1, bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv1d(768, 1536, kernel_size=5, stride=1, padding=2, bias=True)),\n",
        "        (\"bn4\", nn.BatchNorm1d(num_features=1536)),\n",
        "        (\"act4\", nn.ReLU()),\n",
        "        (\"cn4\", nn.Conv1d(1536, 384, kernel_size=5, stride=2, padding=1, bias=True)),\n",
        "    ]))\n",
        "    self.layer4_seModule_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv1d(384, 48, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv1d(48, 384, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_short_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 384, kernel_size=7, stride=9, bias=True)),\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 768, kernel_size=7, stride=2, padding=2, bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv1d(768, 768, kernel_size=7, stride=2, padding=1, bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv1d(768, 1536, kernel_size=7, stride=1, padding=3, bias=True)),\n",
        "        (\"bn4\", nn.BatchNorm1d(num_features=1536)),\n",
        "        (\"act4\", nn.ReLU()),\n",
        "        (\"cn4\", nn.Conv1d(1536, 384, kernel_size=7, stride=2, padding=2, bias=True)),\n",
        "    ]))\n",
        "    self.layer4_seModule_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv1d(384, 48, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv1d(48, 384, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer5_avg_pool1 = nn.AvgPool1d(kernel_size=10)\n",
        "    self.layer5_avg_pool2 = nn.AvgPool1d(kernel_size=10)\n",
        "    self.layer5_avg_pool3 = nn.AvgPool1d(kernel_size=10)\n",
        "\n",
        "    self.fc = nn.Sequential(OrderedDict([\n",
        "        (\"ln1\", nn.Linear(1152, 288)),\n",
        "        (\"dp\", nn.Dropout(p=0.2)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"ln2\", nn.Linear(288, 1)),\n",
        "        (\"sigmoid\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "  def forward(self, x):\n",
        "    #layer1\n",
        "    x = self.layer1_conv2d(x)\n",
        "\n",
        "    #layer2\n",
        "    x = self.layer2_conv2d(x)\n",
        "    u = x\n",
        "    x = x.view(x.size(0), x.size(1), -1).mean(-1).view(x.size(0), x.size(1), 1, 1)\n",
        "    x = self.layer2_seModule(x)\n",
        "    x = u * x\n",
        "\n",
        "    #layer3\n",
        "    x1 = self.layer3_conv2d_block1(x)\n",
        "    u1 = x1\n",
        "    x1 = x1.view(x1.size(0), x1.size(1), -1).mean(-1).view(x1.size(0), x1.size(1), 1, 1)\n",
        "    x1 = self.layer3_seModule_block1(x1)\n",
        "    x1 = u1 * x1\n",
        "\n",
        "    x2 = self.layer3_conv2d_block2(x)\n",
        "    u2 = x2\n",
        "    x2 = x2.view(x2.size(0), x2.size(1), -1).mean(-1).view(x2.size(0), x2.size(1), 1, 1)\n",
        "    x2 = self.layer3_seModule_block2(x2)\n",
        "    x2 = u2 * x2\n",
        "\n",
        "    x3 = self.layer3_conv2d_block3(x)\n",
        "    u3 = x3\n",
        "    x3 = x3.view(x3.size(0), x3.size(1), -1).mean(-1).view(x3.size(0), x3.size(1), 1, 1)\n",
        "    x3 = self.layer3_seModule_block3(x3)\n",
        "    x3 = u3 * x3\n",
        "\n",
        "    #layer4\n",
        "    x1 = torch.flatten(x1, start_dim=1, end_dim=2)\n",
        "    x2 = torch.flatten(x2, start_dim=1, end_dim=2)\n",
        "    x3 = torch.flatten(x3, start_dim=1, end_dim=2)\n",
        "\n",
        "    # x1 = x1.unsqueeze(1)\n",
        "    # x2 = x2.unsqueeze(1)\n",
        "    # x3 = x3.unsqueeze(1)\n",
        "\n",
        "    x1_short = self.layer4_conv1d_short_block1(x1)\n",
        "\n",
        "    x1 = self.layer4_conv1d_block1(x1)\n",
        "    u1 = x1\n",
        "    x1 = x1.view(x1.size(0), x1.size(1), -1).mean(-1).view(x1.size(0), x1.size(1), 1, 1).flatten(2, 3)\n",
        "    x1 = self.layer4_seModule_block1(x1)\n",
        "    x1 = u1 * x1\n",
        "    x1 = x1 + x1_short\n",
        "\n",
        "    x2_short = self.layer4_conv1d_short_block2(x2)\n",
        "\n",
        "    x2 = self.layer4_conv1d_block2(x2)\n",
        "    u2 = x2\n",
        "    x2 = x2.view(x2.size(0), x2.size(1), -1).mean(-1).view(x2.size(0), x2.size(1), 1, 1).flatten(2, 3)\n",
        "    x2 = self.layer4_seModule_block2(x2)\n",
        "    x2 = u2 * x2\n",
        "    x2 = x2 + x2_short\n",
        "\n",
        "    x3_short = self.layer4_conv1d_short_block3(x3)\n",
        "\n",
        "    x3 = self.layer4_conv1d_block3(x3)\n",
        "    u3 = x3\n",
        "    x3 = x3.view(x3.size(0), x3.size(1), -1).mean(-1).view(x3.size(0), x3.size(1), 1, 1).flatten(2, 3)\n",
        "    x3 = self.layer4_seModule_block3(x3)\n",
        "    x3 = u3 * x3\n",
        "    x3 = x3 + x3_short\n",
        "\n",
        "    x1 = self.layer5_avg_pool1(x1)\n",
        "    x2 = self.layer5_avg_pool2(x2)\n",
        "    x3 = self.layer5_avg_pool3(x3)\n",
        "\n",
        "    x = torch.cat((x1, x2, x3), dim=1).flatten(1)\n",
        "\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "r1XSNivRkaEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "3mC8KeqmxMsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(output, target):\n",
        "    train_accuracy = torch.sum(target == output) / len(target)\n",
        "    return train_accuracy\n",
        "\n",
        "def calculate_f1(preds, labels):\n",
        "    tp = torch.sum(preds[labels == preds] == 1)\n",
        "    preds_p = torch.sum(preds == 1)\n",
        "    labels_p = torch.sum(labels == 1)\n",
        "    recall = (tp / labels_p if labels_p != 0 else 0)\n",
        "    precision = (tp / preds_p if preds_p != 0 else 0)\n",
        "    if recall + precision == 0: return 0\n",
        "    return (2 * recall * precision) / (recall + precision)\n",
        "\n",
        "class MetricMonitor:\n",
        "    def __init__(self, float_precision=3):\n",
        "        self.float_precision = float_precision\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
        "\n",
        "    def update(self, metric_name, val):\n",
        "        metric = self.metrics[metric_name]\n",
        "\n",
        "        metric[\"val\"] += val\n",
        "        metric[\"count\"] += 1\n",
        "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \" | \".join(\n",
        "            [\n",
        "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
        "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
        "                )\n",
        "                for (metric_name, metric) in self.metrics.items()\n",
        "            ]\n",
        "        )"
      ],
      "metadata": {
        "id": "iI2rCig7NtIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Valid part"
      ],
      "metadata": {
        "id": "w7gMEMVYxPy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch, device):\n",
        "    metric_monitor = MetricMonitor(float_precision=4)\n",
        "    model.train()\n",
        "    stream = tqdm(train_loader)\n",
        "    for i, batch in enumerate(stream, start=1):\n",
        "        x_batch, y_batch = batch\n",
        "        y_batch = y_batch.to(device, non_blocking=True)\n",
        "        x_batch = x_batch.to(device, non_blocking=True)\n",
        "        output = model(x_batch.float()).view(1, -1)[0]\n",
        "        loss = criterion(output, y_batch.float())\n",
        "        output = (output > 0.5).to(torch.int32)\n",
        "        accuracy = calculate_accuracy(output, y_batch)\n",
        "        f1 = calculate_f1(output, y_batch)\n",
        "        metric_monitor.update(\"Loss\", loss)\n",
        "        metric_monitor.update(\"Accuracy\", accuracy)\n",
        "        metric_monitor.update(\"F1\", f1)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        stream.set_description(\n",
        "            \"Epoch: {epoch}. Train.  {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
        "        )"
      ],
      "metadata": {
        "id": "PdFtCcuhn9k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion, epoch, device):\n",
        "    metric_monitor = MetricMonitor(float_precision=4)\n",
        "    model.eval()\n",
        "    stream = tqdm(val_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(stream, start=1):\n",
        "            x_batch, y_batch = batch\n",
        "            y_batch = y_batch.to(device, non_blocking=True)\n",
        "            x_batch = x_batch.to(device, non_blocking=True)\n",
        "            output = model(x_batch.float()).view(1, -1)[0]\n",
        "            loss = criterion(output, y_batch.float())\n",
        "            output = (output > 0.5).to(torch.int32)\n",
        "            accuracy = calculate_accuracy(output, y_batch)\n",
        "            f1 = calculate_f1(output, y_batch)\n",
        "            metric_monitor.update(\"Loss\", loss)\n",
        "            metric_monitor.update(\"Accuracy\", accuracy)\n",
        "            metric_monitor.update(\"F1\", f1)\n",
        "            stream.set_description(\n",
        "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
        "            )\n",
        "    return metric_monitor.metrics[\"F1\"][\"avg\"], metric_monitor.metrics[\"Accuracy\"][\"avg\"], metric_monitor.metrics[\"Loss\"][\"avg\"]"
      ],
      "metadata": {
        "id": "ACGdfJ3loAJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ECGNet()\n",
        "model = model.to(device)\n",
        "\n",
        "learning_rate = 3e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "\n",
        "loss_fn = FocalLoss(gamma=1.8)"
      ],
      "metadata": {
        "id": "lMyWw32WmVGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login #ключ api wandb\n",
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project=\"Ecg_one_vs_rest\",\n",
        "\n",
        "    config={\n",
        "        \"architecture\": \"ecg_net\",\n",
        "        \"dataset\": \"r_peaks\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "iO5EGQt51uk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjYwjqn3Pgbq",
        "outputId": "1d6bbc0d-e272-4c2e-f766-3d22f1fbcab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "max_f1 = 0.85\n",
        "for epoch in range(num_epochs):\n",
        "  train(train_loader, model, loss_fn, optimizer, epoch, device)\n",
        "  f1_v, acc_v, loss_v = validate(valid_loader, model, loss_fn, epoch, device)\n",
        "  scheduler.step(f1_v)\n",
        "  wandb.log({\"F1\": f1_v, \"Acc\": acc_v, 'loss': loss_v})\n",
        "  if f1_v > max_f1:\n",
        "    max_f1 = f1_v\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/models/{f1_v}.pth')"
      ],
      "metadata": {
        "id": "KqDyEpvez6eO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}